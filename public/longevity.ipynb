{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import xlrd\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# For import export of model\n",
    "import pickle\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# print(plt.style.available)\n",
    "# mpl.style.use(['seaborn']) # optional: for ggplot-like style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file='C:/Users/Abdul Samad/OneDrive - Institute of Business Administration/Work/Tutorials/Machine Learning/Python/Visualizing Data/Canada.xlsx'\n",
    "# df_full=pd.ExcelFile(file) # load spreadsheet\n",
    "# print(df_full.sheet_names) #print the sheets names\n",
    "# df = df_full.parse('Canada by Citizenship', skiprows=range(20), skip_footer=20)\n",
    "\n",
    "# file_path = 'D:/OneDrive - Institute of Business Administration/Work/Duft Und Du/user_fragrance_review.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "unidecode(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ufr_id fba_country_name fba_time_zone  longevity  suitability  \\\n",
       "0       1            Chile        -04:00          1          NaN   \n",
       "1       1            Chile        -04:00          1          NaN   \n",
       "2       1            Chile        -04:00          1          NaN   \n",
       "3       1            Chile        -04:00          1          NaN   \n",
       "4       1            Chile        -04:00          1          NaN   \n",
       "\n",
       "   sustainability           apply_time        wear_off_time  \\\n",
       "0            0.02  2021-02-12 10:58:00  2021-02-12 10:57:00   \n",
       "1            0.02  2021-02-12 10:58:00  2021-02-12 10:57:00   \n",
       "2            0.02  2021-02-12 10:58:00  2021-02-12 10:57:00   \n",
       "3            0.02  2021-02-12 10:58:00  2021-02-12 10:57:00   \n",
       "4            0.02  2021-02-12 10:58:00  2021-02-12 10:57:00   \n",
       "\n",
       "   indoor_time_percentage  number_of_sprays  ...    accord  ingredient  \\\n",
       "0                      54                11  ...  Animalic    Citruses   \n",
       "1                      54                11  ...     Spicy    Citruses   \n",
       "2                      54                11  ...     Sweet    Citruses   \n",
       "3                      54                11  ...  Animalic  Clementine   \n",
       "4                      54                11  ...     Spicy  Clementine   \n",
       "\n",
       "   brand_id  brand  brand_discontinued  brand_tier  bo_location_country  \\\n",
       "0         1  Venom                 NaN        High              Denmark   \n",
       "1         1  Venom                 NaN        High              Denmark   \n",
       "2         1  Venom                 NaN        High              Denmark   \n",
       "3         1  Venom                 NaN        High              Denmark   \n",
       "4         1  Venom                 NaN        High              Denmark   \n",
       "\n",
       "   bo_location_zone  fba_location_country  fba_location_zone  \n",
       "0            +02:00                 Chile             -04:00  \n",
       "1            +02:00                 Chile             -04:00  \n",
       "2            +02:00                 Chile             -04:00  \n",
       "3            +02:00                 Chile             -04:00  \n",
       "4            +02:00                 Chile             -04:00  \n",
       "\n",
       "[5 rows x 55 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ufr_id</th>\n      <th>fba_country_name</th>\n      <th>fba_time_zone</th>\n      <th>longevity</th>\n      <th>suitability</th>\n      <th>sustainability</th>\n      <th>apply_time</th>\n      <th>wear_off_time</th>\n      <th>indoor_time_percentage</th>\n      <th>number_of_sprays</th>\n      <th>...</th>\n      <th>accord</th>\n      <th>ingredient</th>\n      <th>brand_id</th>\n      <th>brand</th>\n      <th>brand_discontinued</th>\n      <th>brand_tier</th>\n      <th>bo_location_country</th>\n      <th>bo_location_zone</th>\n      <th>fba_location_country</th>\n      <th>fba_location_zone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Chile</td>\n      <td>-04:00</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.02</td>\n      <td>2021-02-12 10:58:00</td>\n      <td>2021-02-12 10:57:00</td>\n      <td>54</td>\n      <td>11</td>\n      <td>...</td>\n      <td>Animalic</td>\n      <td>Citruses</td>\n      <td>1</td>\n      <td>Venom</td>\n      <td>NaN</td>\n      <td>High</td>\n      <td>Denmark</td>\n      <td>+02:00</td>\n      <td>Chile</td>\n      <td>-04:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Chile</td>\n      <td>-04:00</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.02</td>\n      <td>2021-02-12 10:58:00</td>\n      <td>2021-02-12 10:57:00</td>\n      <td>54</td>\n      <td>11</td>\n      <td>...</td>\n      <td>Spicy</td>\n      <td>Citruses</td>\n      <td>1</td>\n      <td>Venom</td>\n      <td>NaN</td>\n      <td>High</td>\n      <td>Denmark</td>\n      <td>+02:00</td>\n      <td>Chile</td>\n      <td>-04:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Chile</td>\n      <td>-04:00</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.02</td>\n      <td>2021-02-12 10:58:00</td>\n      <td>2021-02-12 10:57:00</td>\n      <td>54</td>\n      <td>11</td>\n      <td>...</td>\n      <td>Sweet</td>\n      <td>Citruses</td>\n      <td>1</td>\n      <td>Venom</td>\n      <td>NaN</td>\n      <td>High</td>\n      <td>Denmark</td>\n      <td>+02:00</td>\n      <td>Chile</td>\n      <td>-04:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Chile</td>\n      <td>-04:00</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.02</td>\n      <td>2021-02-12 10:58:00</td>\n      <td>2021-02-12 10:57:00</td>\n      <td>54</td>\n      <td>11</td>\n      <td>...</td>\n      <td>Animalic</td>\n      <td>Clementine</td>\n      <td>1</td>\n      <td>Venom</td>\n      <td>NaN</td>\n      <td>High</td>\n      <td>Denmark</td>\n      <td>+02:00</td>\n      <td>Chile</td>\n      <td>-04:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Chile</td>\n      <td>-04:00</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.02</td>\n      <td>2021-02-12 10:58:00</td>\n      <td>2021-02-12 10:57:00</td>\n      <td>54</td>\n      <td>11</td>\n      <td>...</td>\n      <td>Spicy</td>\n      <td>Clementine</td>\n      <td>1</td>\n      <td>Venom</td>\n      <td>NaN</td>\n      <td>High</td>\n      <td>Denmark</td>\n      <td>+02:00</td>\n      <td>Chile</td>\n      <td>-04:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 55 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "## Cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ufr_id                      int64\n",
       "fba_country_name           object\n",
       "fba_time_zone              object\n",
       "longevity                   int64\n",
       "suitability               float64\n",
       "sustainability            float64\n",
       "apply_time                 object\n",
       "wear_off_time              object\n",
       "indoor_time_percentage      int64\n",
       "number_of_sprays            int64\n",
       "projection                float64\n",
       "sillage                   float64\n",
       "like                        int64\n",
       "temp_avg                  float64\n",
       "hum_avg                   float64\n",
       "dew_point_avg             float64\n",
       "uv_index_avg              float64\n",
       "temp_feels_like_avg       float64\n",
       "atm_pressure_avg          float64\n",
       "clouds_avg                float64\n",
       "visibility_avg              int64\n",
       "wind_speed_avg            float64\n",
       "rain_avg                  float64\n",
       "snow_avg                  float64\n",
       "weather_main               object\n",
       "weather_description        object\n",
       "users_id                    int64\n",
       "fp_id                       int64\n",
       "user_check                float64\n",
       "gender                     object\n",
       "dob                        object\n",
       "sweat                     float64\n",
       "height                      int64\n",
       "weight                      int64\n",
       "profession                 object\n",
       "skin_type                  object\n",
       "climate                    object\n",
       "season                     object\n",
       "fp_country                 object\n",
       "fp_time_zone               object\n",
       "fragrance_id                int64\n",
       "fragrance                  object\n",
       "fragrance_gender           object\n",
       "fragrance_discontinued    float64\n",
       "fragrance_type             object\n",
       "accord                     object\n",
       "ingredient                 object\n",
       "brand_id                    int64\n",
       "brand                      object\n",
       "brand_discontinued        float64\n",
       "brand_tier                 object\n",
       "bo_location_country        object\n",
       "bo_location_zone           object\n",
       "fba_location_country       object\n",
       "fba_location_zone          object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ufr_id                      0\n",
       "fba_country_name            0\n",
       "fba_time_zone               0\n",
       "longevity                   0\n",
       "suitability               180\n",
       "sustainability              0\n",
       "apply_time                  0\n",
       "wear_off_time               0\n",
       "indoor_time_percentage      0\n",
       "number_of_sprays            0\n",
       "projection                180\n",
       "sillage                     0\n",
       "like                        0\n",
       "temp_avg                    0\n",
       "hum_avg                     0\n",
       "dew_point_avg               0\n",
       "uv_index_avg                0\n",
       "temp_feels_like_avg         0\n",
       "atm_pressure_avg            0\n",
       "clouds_avg                  0\n",
       "visibility_avg              0\n",
       "wind_speed_avg              0\n",
       "rain_avg                    0\n",
       "snow_avg                  180\n",
       "weather_main                0\n",
       "weather_description         0\n",
       "users_id                    0\n",
       "fp_id                       0\n",
       "user_check                144\n",
       "gender                      0\n",
       "dob                         0\n",
       "sweat                     108\n",
       "height                      0\n",
       "weight                      0\n",
       "profession                  0\n",
       "skin_type                   0\n",
       "climate                     0\n",
       "season                      0\n",
       "fp_country                  0\n",
       "fp_time_zone                0\n",
       "fragrance_id                0\n",
       "fragrance                   0\n",
       "fragrance_gender            0\n",
       "fragrance_discontinued    180\n",
       "fragrance_type              0\n",
       "accord                      0\n",
       "ingredient                  0\n",
       "brand_id                    0\n",
       "brand                       0\n",
       "brand_discontinued        180\n",
       "brand_tier                  0\n",
       "bo_location_country         0\n",
       "bo_location_zone            0\n",
       "fba_location_country        0\n",
       "fba_location_zone           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values\n",
    "# df['suitability'].fillna(df['suitability'].median(), inplace=True)\n",
    "# df['suitability'].fillna(int(df['suitability'].mean()), inplace=True)\n",
    "\n",
    "df['suitability'].fillna(int(0), inplace=True)\n",
    "\n",
    "df['projection'].fillna(int(0), inplace=True)\n",
    "df['rain_avg'].fillna(int(0), inplace=True)\n",
    "df['snow_avg'].fillna(int(0), inplace=True)\n",
    "\n",
    "df['user_check'].fillna(int(0), inplace=True)\n",
    "\n",
    "\n",
    "df['sweat'].fillna(int(df['sweat'].mean()), inplace=True)\n",
    "\n",
    "\n",
    "df['fragrance_discontinued'].fillna(int(0), inplace=True)\n",
    "df['brand_discontinued'].fillna(int(0), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ufr_id                          category\n",
       "fba_country_name                category\n",
       "fba_time_zone                   category\n",
       "longevity                          Int64\n",
       "suitability                        Int64\n",
       "sustainability                   float64\n",
       "apply_time                datetime64[ns]\n",
       "wear_off_time             datetime64[ns]\n",
       "indoor_time_percentage             Int64\n",
       "number_of_sprays                   Int64\n",
       "projection                         Int64\n",
       "sillage                          float64\n",
       "like                               Int64\n",
       "temp_avg                         float64\n",
       "hum_avg                          float64\n",
       "dew_point_avg                    float64\n",
       "uv_index_avg                     float64\n",
       "temp_feels_like_avg              float64\n",
       "atm_pressure_avg                 float64\n",
       "clouds_avg                       float64\n",
       "visibility_avg                     Int64\n",
       "wind_speed_avg                   float64\n",
       "rain_avg                         float64\n",
       "snow_avg                           Int64\n",
       "weather_main                    category\n",
       "weather_description             category\n",
       "users_id                        category\n",
       "fp_id                           category\n",
       "user_check                          bool\n",
       "gender                          category\n",
       "dob                       datetime64[ns]\n",
       "sweat                              Int64\n",
       "height                             Int64\n",
       "weight                             Int64\n",
       "profession                      category\n",
       "skin_type                       category\n",
       "climate                         category\n",
       "season                          category\n",
       "fp_country                      category\n",
       "fp_time_zone                    category\n",
       "fragrance_id                    category\n",
       "fragrance                       category\n",
       "fragrance_gender                category\n",
       "fragrance_discontinued              bool\n",
       "fragrance_type                  category\n",
       "accord                          category\n",
       "ingredient                      category\n",
       "brand_id                        category\n",
       "brand                           category\n",
       "brand_discontinued                  bool\n",
       "brand_tier                      category\n",
       "bo_location_country             category\n",
       "bo_location_zone                category\n",
       "fba_location_country            category\n",
       "fba_location_zone               category\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "df = df.convert_dtypes()\n",
    "\n",
    "# Datetime\n",
    "df['dob']               = df['dob'].astype('datetime64[ns]')\n",
    "df['apply_time']        = df['apply_time'].astype('datetime64[ns]')\n",
    "df['wear_off_time']     = df['wear_off_time'].astype('datetime64[ns]')\n",
    "\n",
    "# Boolean\n",
    "df['user_check']                = df['user_check'].astype('bool')\n",
    "df['fragrance_discontinued']    = df['fragrance_discontinued'].astype('bool')\n",
    "df['brand_discontinued']        = df['brand_discontinued'].astype('bool')\n",
    "\n",
    "# Categorical Variables\n",
    "df[\"ufr_id\"]                = df[\"ufr_id\"].astype(CategoricalDtype(df.ufr_id.unique()))\n",
    "df[\"users_id\"]              = df[\"users_id\"].astype(CategoricalDtype(df.users_id.unique()))\n",
    "df[\"fba_country_name\"]      = df[\"fba_country_name\"].astype(CategoricalDtype(df.fba_country_name.unique()))\n",
    "df[\"fba_time_zone\"]         = df[\"fba_time_zone\"].astype(CategoricalDtype(df.fba_time_zone.unique()))\n",
    "df[\"weather_main\"]          = df[\"weather_main\"].astype(CategoricalDtype(df.weather_main.unique()))\n",
    "df[\"weather_description\"]   = df[\"weather_description\"].astype(CategoricalDtype(df.weather_description.unique()))\n",
    "df[\"fp_id\"]                 = df[\"fp_id\"].astype(CategoricalDtype(df.fp_id.unique()))\n",
    "df[\"gender\"]                = df[\"gender\"].astype(CategoricalDtype(df.gender.unique()))\n",
    "df[\"profession\"]            = df[\"profession\"].astype(CategoricalDtype(df.profession.unique()))\n",
    "df[\"skin_type\"]             = df[\"skin_type\"].astype(CategoricalDtype(df.skin_type.unique()))\n",
    "df[\"climate\"]               = df[\"climate\"].astype(CategoricalDtype(df.climate.unique()))\n",
    "df[\"season\"]                = df[\"season\"].astype(CategoricalDtype(df.season.unique()))\n",
    "df[\"fp_country\"]            = df[\"fp_country\"].astype(CategoricalDtype(df.fp_country.unique()))\n",
    "df[\"fp_time_zone\"]          = df[\"fp_time_zone\"].astype(CategoricalDtype(df.fp_time_zone.unique()))\n",
    "df[\"fragrance_id\"]          = df[\"fragrance_id\"].astype(CategoricalDtype(df.fragrance_id.unique()))\n",
    "df[\"fragrance\"]             = df[\"fragrance\"].astype(CategoricalDtype(df.fragrance.unique()))\n",
    "df[\"fragrance_gender\"]      = df[\"fragrance_gender\"].astype(CategoricalDtype(df.fragrance_gender.unique()))\n",
    "df[\"fragrance_type\"]        = df[\"fragrance_type\"].astype(CategoricalDtype(df.fragrance_type.unique()))\n",
    "df[\"accord\"]                = df[\"accord\"].astype(CategoricalDtype(df.accord.unique()))\n",
    "df[\"ingredient\"]            = df[\"ingredient\"].astype(CategoricalDtype(df.ingredient.unique()))\n",
    "df[\"brand_id\"]              = df[\"brand_id\"].astype(CategoricalDtype(df.brand_id.unique()))\n",
    "df[\"brand\"]                 = df[\"brand\"].astype(CategoricalDtype(df.brand.unique()))\n",
    "df[\"brand_tier\"]            = df[\"brand_tier\"].astype(CategoricalDtype(df.brand_tier.unique()))\n",
    "df[\"bo_location_country\"]   = df[\"bo_location_country\"].astype(CategoricalDtype(df.bo_location_country.unique()))\n",
    "df[\"bo_location_zone\"]      = df[\"bo_location_zone\"].astype(CategoricalDtype(df.bo_location_zone.unique()))\n",
    "df[\"fba_location_country\"]  = df[\"fba_location_country\"].astype(CategoricalDtype(df.fba_location_country.unique()))\n",
    "df[\"fba_location_zone\"]     = df[\"fba_location_zone\"].astype(CategoricalDtype(df.fba_location_zone.unique()))\n",
    "\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualting Age\n",
    "\n",
    "now = pd.to_datetime('now')\n",
    "df['age'] = (now - df['dob']).dt.total_seconds() / (60*60*24*365.25)\n",
    "df.drop(['dob'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting out Dates\n",
    "\n",
    "# Apply Time\n",
    "df['apply_time_year']          = df['apply_time'].dt.year\n",
    "df['apply_time_month']         = df['apply_time'].dt.month\n",
    "df['apply_time_day']           = df['apply_time'].dt.day\n",
    "df['apply_time_hour']          = df['apply_time'].dt.hour\n",
    "df['apply_time_minute']        = df['apply_time'].dt.minute\n",
    "df['apply_time_weekday_name']  = df['apply_time'].dt.day_name()\n",
    "\n",
    "# Wear Off Time\n",
    "df['wear_off_time_year']          = df['wear_off_time'].dt.year\n",
    "df['wear_off_time_month']         = df['wear_off_time'].dt.month\n",
    "df['wear_off_time_day']           = df['wear_off_time'].dt.day\n",
    "df['wear_off_time_hour']          = df['wear_off_time'].dt.hour\n",
    "df['wear_off_time_minute']        = df['wear_off_time'].dt.minute\n",
    "df['wear_off_time_weekday_name']  = df['wear_off_time'].dt.day_name()\n",
    "\n",
    "# Type Cast\n",
    "df['age']               = df['age'].astype('float')\n",
    "\n",
    "# Drop Apply Time & Wear Off Time\n",
    "df.drop(['apply_time'],axis=1, inplace=True)\n",
    "df.drop(['wear_off_time'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       longevity  suitability  sustainability  indoor_time_percentage  \\\n",
       "count      180.0        180.0    1.800000e+02                   180.0   \n",
       "mean         1.0          0.0    2.000000e-02                    54.0   \n",
       "std          0.0          0.0    1.391650e-17                     0.0   \n",
       "min          1.0          0.0    2.000000e-02                    54.0   \n",
       "25%          1.0          0.0    2.000000e-02                    54.0   \n",
       "50%          1.0          0.0    2.000000e-02                    54.0   \n",
       "75%          1.0          0.0    2.000000e-02                    54.0   \n",
       "max          1.0          0.0    2.000000e-02                    54.0   \n",
       "\n",
       "       number_of_sprays  projection  sillage   like      temp_avg  \\\n",
       "count             180.0       180.0    180.0  180.0  1.800000e+02   \n",
       "mean               11.0         0.0     22.5   53.0  8.143000e+01   \n",
       "std                 0.0         0.0      0.0    0.0  1.852564e-13   \n",
       "min                11.0         0.0     22.5   53.0  8.143000e+01   \n",
       "25%                11.0         0.0     22.5   53.0  8.143000e+01   \n",
       "50%                11.0         0.0     22.5   53.0  8.143000e+01   \n",
       "75%                11.0         0.0     22.5   53.0  8.143000e+01   \n",
       "max                11.0         0.0     22.5   53.0  8.143000e+01   \n",
       "\n",
       "            hum_avg  ...  apply_time_year  apply_time_month  apply_time_day  \\\n",
       "count  1.800000e+02  ...            180.0             180.0           180.0   \n",
       "mean   7.538000e+01  ...           2021.0               2.0            12.0   \n",
       "std    2.565089e-13  ...              0.0               0.0             0.0   \n",
       "min    7.538000e+01  ...           2021.0               2.0            12.0   \n",
       "25%    7.538000e+01  ...           2021.0               2.0            12.0   \n",
       "50%    7.538000e+01  ...           2021.0               2.0            12.0   \n",
       "75%    7.538000e+01  ...           2021.0               2.0            12.0   \n",
       "max    7.538000e+01  ...           2021.0               2.0            12.0   \n",
       "\n",
       "       apply_time_hour  apply_time_minute  wear_off_time_year  \\\n",
       "count            180.0              180.0               180.0   \n",
       "mean              10.0               58.0              2021.0   \n",
       "std                0.0                0.0                 0.0   \n",
       "min               10.0               58.0              2021.0   \n",
       "25%               10.0               58.0              2021.0   \n",
       "50%               10.0               58.0              2021.0   \n",
       "75%               10.0               58.0              2021.0   \n",
       "max               10.0               58.0              2021.0   \n",
       "\n",
       "       wear_off_time_month  wear_off_time_day  wear_off_time_hour  \\\n",
       "count                180.0              180.0               180.0   \n",
       "mean                   2.0               12.0                10.0   \n",
       "std                    0.0                0.0                 0.0   \n",
       "min                    2.0               12.0                10.0   \n",
       "25%                    2.0               12.0                10.0   \n",
       "50%                    2.0               12.0                10.0   \n",
       "75%                    2.0               12.0                10.0   \n",
       "max                    2.0               12.0                10.0   \n",
       "\n",
       "       wear_off_time_minute  \n",
       "count                 180.0  \n",
       "mean                   57.0  \n",
       "std                     0.0  \n",
       "min                    57.0  \n",
       "25%                    57.0  \n",
       "50%                    57.0  \n",
       "75%                    57.0  \n",
       "max                    57.0  \n",
       "\n",
       "[8 rows x 33 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longevity</th>\n      <th>suitability</th>\n      <th>sustainability</th>\n      <th>indoor_time_percentage</th>\n      <th>number_of_sprays</th>\n      <th>projection</th>\n      <th>sillage</th>\n      <th>like</th>\n      <th>temp_avg</th>\n      <th>hum_avg</th>\n      <th>...</th>\n      <th>apply_time_year</th>\n      <th>apply_time_month</th>\n      <th>apply_time_day</th>\n      <th>apply_time_hour</th>\n      <th>apply_time_minute</th>\n      <th>wear_off_time_year</th>\n      <th>wear_off_time_month</th>\n      <th>wear_off_time_day</th>\n      <th>wear_off_time_hour</th>\n      <th>wear_off_time_minute</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>1.800000e+02</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>1.800000e+02</td>\n      <td>1.800000e+02</td>\n      <td>...</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>54.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>22.5</td>\n      <td>53.0</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>...</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>58.0</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>57.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.391650e-17</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.852564e-13</td>\n      <td>2.565089e-13</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>54.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>22.5</td>\n      <td>53.0</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>...</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>58.0</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>57.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>54.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>22.5</td>\n      <td>53.0</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>...</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>58.0</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>57.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>54.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>22.5</td>\n      <td>53.0</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>...</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>58.0</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>57.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>54.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>22.5</td>\n      <td>53.0</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>...</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>58.0</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>57.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>54.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>22.5</td>\n      <td>53.0</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>...</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>58.0</td>\n      <td>2021.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>57.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd.concat to join the new columns with your original dataframe\n",
    "df = pd.concat([df,pd.get_dummies(df['ufr_id'], prefix='ufr_id')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['users_id'], prefix='users_id')],axis=1)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['apply_time_weekday_name'], prefix='apply_time_weekday_name')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['wear_off_time_weekday_name'], prefix='wear_off_time_weekday_name')],axis=1)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['fba_country_name'], prefix='fba_country_name')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['fba_time_zone'], prefix='fba_time_zone')],axis=1)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['weather_main'], prefix='weather_main')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['weather_description'], prefix='weather_description')],axis=1)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['fp_id'], prefix='fp_id')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['gender'], prefix='gender')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['profession'], prefix='profession')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['skin_type'], prefix='skin_type')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['climate'], prefix='climate')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['season'], prefix='season')],axis=1)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['fp_country'], prefix='fp_country')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['fp_time_zone'], prefix='fp_time_zone')],axis=1)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['fragrance_id'], prefix='fragrance_id')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['fragrance'], prefix='fragrance')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['fragrance_gender'], prefix='fragrance_gender')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['fragrance_type'], prefix='fragrance_type')],axis=1)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['accord'], prefix='accord')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['ingredient'], prefix='ingredient')],axis=1)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['brand_id'], prefix='brand_id')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['brand'], prefix='brand')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['brand_tier'], prefix='brand_tier')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['bo_location_country'], prefix='bo_location_country')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['bo_location_zone'], prefix='bo_location_zone')],axis=1)\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['fba_location_country'], prefix='fba_location_country')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['fba_location_zone'], prefix='fba_location_zone')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "df.drop(['ufr_id'],axis=1, inplace=True)\n",
    "df.drop(['users_id'],axis=1, inplace=True)\n",
    "\n",
    "df.drop(['apply_time_weekday_name'],axis=1, inplace=True)\n",
    "df.drop(['wear_off_time_weekday_name'],axis=1, inplace=True)\n",
    "\n",
    "df.drop(['fba_country_name'],axis=1, inplace=True)\n",
    "df.drop(['fba_time_zone'],axis=1, inplace=True)\n",
    "\n",
    "df.drop(['weather_main'],axis=1, inplace=True)\n",
    "df.drop(['weather_description'],axis=1, inplace=True)\n",
    "\n",
    "df.drop(['fp_id'],axis=1, inplace=True)\n",
    "df.drop(['gender'],axis=1, inplace=True)\n",
    "df.drop(['profession'],axis=1, inplace=True)\n",
    "df.drop(['skin_type'],axis=1, inplace=True)\n",
    "df.drop(['climate'],axis=1, inplace=True)\n",
    "df.drop(['season'],axis=1, inplace=True)\n",
    "\n",
    "df.drop(['fp_country'],axis=1, inplace=True)\n",
    "df.drop(['fp_time_zone'],axis=1, inplace=True)\n",
    "\n",
    "df.drop(['fragrance_id'],axis=1, inplace=True)\n",
    "df.drop(['fragrance'],axis=1, inplace=True)\n",
    "df.drop(['fragrance_gender'],axis=1, inplace=True)\n",
    "df.drop(['fragrance_type'],axis=1, inplace=True)\n",
    "\n",
    "df.drop(['accord'],axis=1, inplace=True)\n",
    "df.drop(['ingredient'],axis=1, inplace=True)\n",
    "\n",
    "df.drop(['brand_id'],axis=1, inplace=True)\n",
    "df.drop(['brand'],axis=1, inplace=True)\n",
    "df.drop(['brand_tier'],axis=1, inplace=True)\n",
    "df.drop(['bo_location_country'],axis=1, inplace=True)\n",
    "df.drop(['bo_location_zone'],axis=1, inplace=True)\n",
    "\n",
    "df.drop(['fba_location_country'],axis=1, inplace=True)\n",
    "df.drop(['fba_location_zone'],axis=1, inplace=True)\n",
    "\n",
    "# To Be Included Later\n",
    "df.drop(['indoor_time_percentage'],axis=1, inplace=True)\n",
    "df.drop(['number_of_sprays'],axis=1, inplace=True)\n",
    "df.drop(['projection'],axis=1, inplace=True)\n",
    "df.drop(['sillage'],axis=1, inplace=True)\n",
    "df.drop(['like'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(180, 89)\n0\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.duplicated(keep='first').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   longevity  suitability  sustainability  temp_avg  hum_avg  dew_point_avg  \\\n",
       "0          1            0            0.02     81.43    75.38          73.02   \n",
       "1          1            0            0.02     81.43    75.38          73.02   \n",
       "2          1            0            0.02     81.43    75.38          73.02   \n",
       "3          1            0            0.02     81.43    75.38          73.02   \n",
       "4          1            0            0.02     81.43    75.38          73.02   \n",
       "\n",
       "   uv_index_avg  temp_feels_like_avg  atm_pressure_avg  clouds_avg  ...  \\\n",
       "0          14.1                83.08           1010.75       44.62  ...   \n",
       "1          14.1                83.08           1010.75       44.62  ...   \n",
       "2          14.1                83.08           1010.75       44.62  ...   \n",
       "3          14.1                83.08           1010.75       44.62  ...   \n",
       "4          14.1                83.08           1010.75       44.62  ...   \n",
       "\n",
       "   brand_Venom  brand_tier_High  bo_location_country_Denmark  \\\n",
       "0            1                1                            1   \n",
       "1            1                1                            1   \n",
       "2            1                1                            1   \n",
       "3            1                1                            1   \n",
       "4            1                1                            1   \n",
       "\n",
       "   bo_location_zone_+02:00  fba_location_country_Chile  \\\n",
       "0                        1                           1   \n",
       "1                        1                           1   \n",
       "2                        1                           1   \n",
       "3                        1                           1   \n",
       "4                        1                           1   \n",
       "\n",
       "   fba_location_country_Aland Islands  fba_location_country_Algeria  \\\n",
       "0                                   0                             0   \n",
       "1                                   0                             0   \n",
       "2                                   0                             0   \n",
       "3                                   0                             0   \n",
       "4                                   0                             0   \n",
       "\n",
       "   fba_location_zone_-04:00  fba_location_zone_+03:00  \\\n",
       "0                         1                         0   \n",
       "1                         1                         0   \n",
       "2                         1                         0   \n",
       "3                         1                         0   \n",
       "4                         1                         0   \n",
       "\n",
       "   fba_location_zone_+01:00  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longevity</th>\n      <th>suitability</th>\n      <th>sustainability</th>\n      <th>temp_avg</th>\n      <th>hum_avg</th>\n      <th>dew_point_avg</th>\n      <th>uv_index_avg</th>\n      <th>temp_feels_like_avg</th>\n      <th>atm_pressure_avg</th>\n      <th>clouds_avg</th>\n      <th>...</th>\n      <th>brand_Venom</th>\n      <th>brand_tier_High</th>\n      <th>bo_location_country_Denmark</th>\n      <th>bo_location_zone_+02:00</th>\n      <th>fba_location_country_Chile</th>\n      <th>fba_location_country_Aland Islands</th>\n      <th>fba_location_country_Algeria</th>\n      <th>fba_location_zone_-04:00</th>\n      <th>fba_location_zone_+03:00</th>\n      <th>fba_location_zone_+01:00</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.02</td>\n      <td>81.43</td>\n      <td>75.38</td>\n      <td>73.02</td>\n      <td>14.1</td>\n      <td>83.08</td>\n      <td>1010.75</td>\n      <td>44.62</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.02</td>\n      <td>81.43</td>\n      <td>75.38</td>\n      <td>73.02</td>\n      <td>14.1</td>\n      <td>83.08</td>\n      <td>1010.75</td>\n      <td>44.62</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.02</td>\n      <td>81.43</td>\n      <td>75.38</td>\n      <td>73.02</td>\n      <td>14.1</td>\n      <td>83.08</td>\n      <td>1010.75</td>\n      <td>44.62</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.02</td>\n      <td>81.43</td>\n      <td>75.38</td>\n      <td>73.02</td>\n      <td>14.1</td>\n      <td>83.08</td>\n      <td>1010.75</td>\n      <td>44.62</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.02</td>\n      <td>81.43</td>\n      <td>75.38</td>\n      <td>73.02</td>\n      <td>14.1</td>\n      <td>83.08</td>\n      <td>1010.75</td>\n      <td>44.62</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 89 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this and fix this\n",
    "# aggregation_functions = {'longevity': 'first', 'amount': 'sum', 'name': 'first'}\n",
    "# df_new = df.groupby(df['ufr_id']).aggregate(aggregation_functions)\n",
    "# df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(180, 89)"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_long.head()\n",
    "# df_suit.head()\n",
    "# df_sust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       longevity  suitability  sustainability      temp_avg       hum_avg  \\\n",
       "count      180.0        180.0    1.800000e+02  1.800000e+02  1.800000e+02   \n",
       "mean         1.0          0.0    2.000000e-02  8.143000e+01  7.538000e+01   \n",
       "std          0.0          0.0    1.391650e-17  1.852564e-13  2.565089e-13   \n",
       "min          1.0          0.0    2.000000e-02  8.143000e+01  7.538000e+01   \n",
       "25%          1.0          0.0    2.000000e-02  8.143000e+01  7.538000e+01   \n",
       "50%          1.0          0.0    2.000000e-02  8.143000e+01  7.538000e+01   \n",
       "75%          1.0          0.0    2.000000e-02  8.143000e+01  7.538000e+01   \n",
       "max          1.0          0.0    2.000000e-02  8.143000e+01  7.538000e+01   \n",
       "\n",
       "       dew_point_avg  uv_index_avg  temp_feels_like_avg  atm_pressure_avg  \\\n",
       "count   1.800000e+02  1.800000e+02         1.800000e+02            180.00   \n",
       "mean    7.302000e+01  1.410000e+01         8.308000e+01           1010.75   \n",
       "std     2.992604e-13  4.809542e-14         5.700198e-14              0.00   \n",
       "min     7.302000e+01  1.410000e+01         8.308000e+01           1010.75   \n",
       "25%     7.302000e+01  1.410000e+01         8.308000e+01           1010.75   \n",
       "50%     7.302000e+01  1.410000e+01         8.308000e+01           1010.75   \n",
       "75%     7.302000e+01  1.410000e+01         8.308000e+01           1010.75   \n",
       "max     7.302000e+01  1.410000e+01         8.308000e+01           1010.75   \n",
       "\n",
       "         clouds_avg  ...  brand_Venom  brand_tier_High  \\\n",
       "count  1.800000e+02  ...        180.0            180.0   \n",
       "mean   4.462000e+01  ...          1.0              1.0   \n",
       "std    9.262821e-14  ...          0.0              0.0   \n",
       "min    4.462000e+01  ...          1.0              1.0   \n",
       "25%    4.462000e+01  ...          1.0              1.0   \n",
       "50%    4.462000e+01  ...          1.0              1.0   \n",
       "75%    4.462000e+01  ...          1.0              1.0   \n",
       "max    4.462000e+01  ...          1.0              1.0   \n",
       "\n",
       "       bo_location_country_Denmark  bo_location_zone_+02:00  \\\n",
       "count                        180.0                    180.0   \n",
       "mean                           1.0                      1.0   \n",
       "std                            0.0                      0.0   \n",
       "min                            1.0                      1.0   \n",
       "25%                            1.0                      1.0   \n",
       "50%                            1.0                      1.0   \n",
       "75%                            1.0                      1.0   \n",
       "max                            1.0                      1.0   \n",
       "\n",
       "       fba_location_country_Chile  fba_location_country_Aland Islands  \\\n",
       "count                  180.000000                          180.000000   \n",
       "mean                     0.333333                            0.333333   \n",
       "std                      0.472719                            0.472719   \n",
       "min                      0.000000                            0.000000   \n",
       "25%                      0.000000                            0.000000   \n",
       "50%                      0.000000                            0.000000   \n",
       "75%                      1.000000                            1.000000   \n",
       "max                      1.000000                            1.000000   \n",
       "\n",
       "       fba_location_country_Algeria  fba_location_zone_-04:00  \\\n",
       "count                    180.000000                180.000000   \n",
       "mean                       0.333333                  0.333333   \n",
       "std                        0.472719                  0.472719   \n",
       "min                        0.000000                  0.000000   \n",
       "25%                        0.000000                  0.000000   \n",
       "50%                        0.000000                  0.000000   \n",
       "75%                        1.000000                  1.000000   \n",
       "max                        1.000000                  1.000000   \n",
       "\n",
       "       fba_location_zone_+03:00  fba_location_zone_+01:00  \n",
       "count                180.000000                180.000000  \n",
       "mean                   0.333333                  0.333333  \n",
       "std                    0.472719                  0.472719  \n",
       "min                    0.000000                  0.000000  \n",
       "25%                    0.000000                  0.000000  \n",
       "50%                    0.000000                  0.000000  \n",
       "75%                    1.000000                  1.000000  \n",
       "max                    1.000000                  1.000000  \n",
       "\n",
       "[8 rows x 86 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longevity</th>\n      <th>suitability</th>\n      <th>sustainability</th>\n      <th>temp_avg</th>\n      <th>hum_avg</th>\n      <th>dew_point_avg</th>\n      <th>uv_index_avg</th>\n      <th>temp_feels_like_avg</th>\n      <th>atm_pressure_avg</th>\n      <th>clouds_avg</th>\n      <th>...</th>\n      <th>brand_Venom</th>\n      <th>brand_tier_High</th>\n      <th>bo_location_country_Denmark</th>\n      <th>bo_location_zone_+02:00</th>\n      <th>fba_location_country_Chile</th>\n      <th>fba_location_country_Aland Islands</th>\n      <th>fba_location_country_Algeria</th>\n      <th>fba_location_zone_-04:00</th>\n      <th>fba_location_zone_+03:00</th>\n      <th>fba_location_zone_+01:00</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>1.800000e+02</td>\n      <td>1.800000e+02</td>\n      <td>1.800000e+02</td>\n      <td>1.800000e+02</td>\n      <td>1.800000e+02</td>\n      <td>1.800000e+02</td>\n      <td>180.00</td>\n      <td>1.800000e+02</td>\n      <td>...</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.0</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>7.302000e+01</td>\n      <td>1.410000e+01</td>\n      <td>8.308000e+01</td>\n      <td>1010.75</td>\n      <td>4.462000e+01</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.391650e-17</td>\n      <td>1.852564e-13</td>\n      <td>2.565089e-13</td>\n      <td>2.992604e-13</td>\n      <td>4.809542e-14</td>\n      <td>5.700198e-14</td>\n      <td>0.00</td>\n      <td>9.262821e-14</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.472719</td>\n      <td>0.472719</td>\n      <td>0.472719</td>\n      <td>0.472719</td>\n      <td>0.472719</td>\n      <td>0.472719</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>7.302000e+01</td>\n      <td>1.410000e+01</td>\n      <td>8.308000e+01</td>\n      <td>1010.75</td>\n      <td>4.462000e+01</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>7.302000e+01</td>\n      <td>1.410000e+01</td>\n      <td>8.308000e+01</td>\n      <td>1010.75</td>\n      <td>4.462000e+01</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>7.302000e+01</td>\n      <td>1.410000e+01</td>\n      <td>8.308000e+01</td>\n      <td>1010.75</td>\n      <td>4.462000e+01</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>7.302000e+01</td>\n      <td>1.410000e+01</td>\n      <td>8.308000e+01</td>\n      <td>1010.75</td>\n      <td>4.462000e+01</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.000000e-02</td>\n      <td>8.143000e+01</td>\n      <td>7.538000e+01</td>\n      <td>7.302000e+01</td>\n      <td>1.410000e+01</td>\n      <td>8.308000e+01</td>\n      <td>1010.75</td>\n      <td>4.462000e+01</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 86 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longevity\n",
    "df_long = df[df.columns.difference(['suitability',  'sustainability'], sort=False)]\n",
    "df_suit = df[df.columns.difference(['longevity',    'sustainability'], sort=False)]\n",
    "df_sust = df[df.columns.difference(['longevity',    'suitability'], sort=False)]\n"
   ]
  },
  {
   "source": [
    "## Train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Longevity\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variable (dependent variable) as y\n",
    "y = df.longevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(144, 89) (144,)\n(36, 89) (36,)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "source": [
    "## Evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The line / model\n",
    "# plt.scatter(y_test, predictions)\n",
    "# plt.xlabel(“True Values”)\n",
    "# plt.ylabel(“Predictions”)"
   ]
  },
  {
   "source": [
    "## Save the model in pickle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickling the list\n",
    "file = open('model', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "list_pickle = pickle.dump(model, file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file to \n",
    "file = open('model', 'rb')\n",
    "\n",
    "# Load model from the file\n",
    "loaded_pickle = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "loaded_pickle"
   ]
  },
  {
   "source": [
    "# END"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = diabetes.longevity # define the target variable (dependent variable) as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.regplot(x = 'year', y = 'total', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['AREA','REG','DEV','Type','Coverage'], axis=1, inplace=True)\n",
    "# df.rename(columns={'OdName':'Country', 'AreaName':'Continent', 'RegName':'Region'}, inplace=True)\n",
    "# df['Total'] = df.sum(axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.set_index('Country', inplace=True)\n",
    "# df.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = list(map(str, df.columns))\n",
    "\n",
    "# years = list(map(str, range(1980, 2014)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values('Total', ascending=False, axis=0, inplace=True)\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values('Total', ascending=False, axis=0, inplace=True)\n",
    "\n",
    "# # dft = df.loc('Unknown')\n",
    "# # df.drop(df.loc('Unknown'))\n",
    "# dft = df.drop(index = 'Unknown')\n",
    "# dft = dft.drop(index = 'Total')\n",
    "\n",
    "# # get the top 5 entries\n",
    "# # df_top5 = df[1:6]\n",
    "# # df_top5 = dft.head()\n",
    "\n",
    "# # transpose the dataframe\n",
    "# # df_top5 = df_top5[years].transpose() \n",
    "\n",
    "# # df_top5.head()\n",
    "\n",
    "# # we can use the sum() method to get the total population per year\n",
    "# df_tot = pd.DataFrame(dft[years].sum(axis=0))\n",
    "\n",
    "# # change the years to type float (useful for regression later on)\n",
    "# df_tot.index = map(float, df_tot.index)\n",
    "\n",
    "# # reset the index to put in back in as a column in the df_tot dataframe\n",
    "# df_tot.reset_index(inplace=True)\n",
    "\n",
    "# # rename columns\n",
    "# df_tot.columns = ['year', 'total']\n",
    "\n",
    "# # view the final dataframe\n",
    "# df_tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.regplot(x='year', y='total', data=df_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.regplot(x='year', y='total', data=df_tot, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 10))\n",
    "# ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+', scatter_kws={'s': 200})\n",
    "\n",
    "# ax.set(xlabel='Year', ylabel='Total Immigration') # add x- and y-labels\n",
    "# ax.set_title('Total Immigration to Canada from 1980 - 2013') # add title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 10))\n",
    "\n",
    "# sns.set(font_scale=1.5)\n",
    "\n",
    "# ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+', scatter_kws={'s': 200})\n",
    "# ax.set(xlabel='Year', ylabel='Total Immigration')\n",
    "# ax.set_title('Total Immigration to Canada from 1980 - 2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 10))\n",
    "\n",
    "# sns.set(font_scale=1.5)\n",
    "# sns.set_style('ticks') # change background to white background\n",
    "\n",
    "# ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+', scatter_kws={'s': 200})\n",
    "# ax.set(xlabel='Year', ylabel='Total Immigration')\n",
    "# ax.set_title('Total Immigration to Canada from 1980 - 2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 10))\n",
    "\n",
    "# sns.set(font_scale=1.5)\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "# ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+', scatter_kws={'s': 200})\n",
    "# ax.set(xlabel='Year', ylabel='Total Immigration')\n",
    "# ax.set_title('Total Immigration to Canada from 1980 - 2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### type your answer here\n",
    "\n",
    "# dfr = dft.loc[['Denmark', 'Sweden', 'Norway'], years].transpose()\n",
    "\n",
    "# df_total = pd.DataFrame(dfr.sum(axis=1))\n",
    "\n",
    "# df_total.reset_index(inplace=True)\n",
    "\n",
    "# df_total.columns = ['year', 'total']\n",
    "# df_total.head()\n",
    "\n",
    "# df_total['year'] = df_total['year'].astype(int)\n",
    "\n",
    "# plt.figure(figsize = (15,10))\n",
    "\n",
    "# sns.set_style('whitegrid')\n",
    "# sns.set(font_scale=1.5)\n",
    "\n",
    "# ax = sns.regplot(x='year', y='total', data=df_total, color='red', marker='+', scatter_kws={'s': 200})\n",
    "# ax.set(xlabel='Year', ylabel='Total Immigration')\n",
    "# ax.set_title('Total Immigrationn from Denmark, Sweden, and Norway to Canada from 1980 - 2013\\n')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}